{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mgBrAuCKRFm"
   },
   "source": [
    "## install reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GBjdazSm4cr",
    "outputId": "79d29c6d-84b5-4df1-b7b3-0e3ead208531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow seaborn matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pozp0-Y6Jak3"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## connecting to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0xBOY6wmIoa",
    "outputId": "e1a39181-979f-4cd5-8622-c7ac9a3fa572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "['VID_20210528_174657_178.mp4', 'VID_20210528_174701_440.mp4', 'Infrastructure VS. AD-HOC.pdf.gdrive', 'افكار لكتابه السيره الذاتية.gdoc', 'British Council Certificate.pdf', 'IMG_20211010_131359 (4).jpg', 'IMG_20211010_131359 (3).jpg', 'IMG_20211010_131359 (2).jpg', 'IMG_20211010_131359 (1).jpg', 'IMG_20211010_131359.jpg', 'IMG_20211010_192217.jpg', 'Screenshot_2021-10-21-11-18-21-80_40deb401b9ffe8e1df2f1cc5ba480b12.jpg', 'exp1s.pdf', 'EXP2.pdf', 'KIRSSOF.pdf', '16372573386196998407231969063766.jpg', '16372575382426078223689767951657.jpg', '555555.pdf', 'abdelrhman Zain Mohamed 2101646(2).pdf', 'EXP 5.pdf', 'EXP 6.pdf', 'Abdelrhman zain mohamed 2101646(3).pdf', 'نسخة من Sections 7 & 8.pdf', 'exp1sssss.pdf', 'abdelrhman zain 1 .pdf', 'ABDELRHman zain 2 pdf.pdf', 'ABDEL rhman zain . 3.pdf', 'exp measure 4 .pdf', 'Introduction.pdf', 'exp 6.pdf', 'exp 7.pdf', 'exp 8.pdf', 'exp9.pdf', 'exp 10  (1).pdf', 'exp 10 .pdf', 'exp 11 .pdf', 'abdelrhman zain.pptx', 'project montage.mp4', 'exp12.pdf', 'exp 11 correct .pdf', 'measurements sheet 4.pdf', 'abdelrhman zain 3.pdf', 'Course_Certificate_En.pdf', 'كلية.pdf', 'zain.jpeg', 'نسخة من Spring 2021.pdf', 'PicsArt_07-06-02.27.24.jpg', 'download-pdf-ebooks.org-1470055289-363.pdf', 'zain info.pdf', 'CS50x (1).pdf', 'Abdelrhman zain mohamed ahmed', '572638bc-18f0-4ec9-aefb-ba20c3f479c3.pdf', 'Screenshot_2022-09-24-16-19-54-35_40deb401b9ffe8e1df2f1cc5ba480b12.jpg', 'my new cv.pdf', 'تحديد معاد سكشن (fundamental (section 8,33,34,35.gform', 'IMG_20221103_121122.jpg', 'NEW_PCB_2023-01-30.pcbdoc', 'PROJECT', 'نسخة من Day 16 part 2.mkv', 'نسخة من (Spring 2021) Midterm Exam.pdf', 'WhatsApp Image 2023-04-13 at 14.26.32.jpg', 'WhatsApp Image 2023-04-13 at 14.27.07.jpg', 'WhatsApp Image 2023-04-13 at 14.27.16.jpg', 'my  cv.pdf', 'Copy of [6] Mosfet and Gates.pdf', 'university id.pdf', 'Emailing my  cv.pdf', 'نموذج بدون عنوان (1).gform', 'NAID', 'CamScanner 08-26-2023 15.06_1.jpg', 'Abdelrahman Zain Mohamed Ahmed.pdf', 'نسخة من CamScanner 08-26-2023 15.06_1.jpg', 'Python_Essentials_1_Badge20230908-28-5nzv7a.pdf', 'نموذج بدون عنوان.gform', \"Abdelrhman Zain's CV (1).pdf\", 'Python_Essentials_2_Badge20230922-30-rpmyck.pdf', \"Abdelrhman zain'CV.pdf\", 'Coursera KMQ3U8YBAT29.pdf', 'Classroom', 'control assignment.pdf', 'CamScanner 12-06-2023 18.29_1.jpg', 'my_data.pdf', 'data intern.pdf', 'التعهد.pdf', 'نسخة من 2013.pdf', 'Lab 3&4 .pdf', 'Lab 1&2.pdf', 'Lab 5&6.pdf', 'lab 7 & 8.pdf', 'Lab 9&10.pdf', 'Lab 11&12 .pdf', 'assignment 2 control.pdf', 'assignment 3,4.pdf', \"Abdelrhman Zain's CV.pdf\", 'الاقرار.pdf', 'Emailing lab3_algo_zain.pdf', 'abdelrhman zain(1) (4).pdf', 'abdelrhman zain(1) (3).pdf', 'abdelrhman zain(1) (2).pdf', 'abdelrhman zain(1) (1).pdf', 'abdelrhman zain(1).pdf', 'Abdelrhman Zain_CV_For_WideBot (1).pdf', 'Abdelrhman Zain_CV_For_Ejada.pdf', 'Abdelrhman Zain_CV_For_WideBot.pdf', 'اقرار.pdf', 'Abdelrhman_Zain.pdf', 'YouCut_20240723_233854680.mp4', 'Abdelrhman Zain.pdf', 'Google AI Studio', 'Teams CVs', 'Abdelrhman Zain Mohamed Ahmed.pdf', 'DL-ASU_Task_00', 'Colab Notebooks', 'Teeth_Dataset']\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "# List the contents of your shared drives\n",
    "print(os.listdir('/content/drive/MyDrive'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUnsVZjmJkQw"
   },
   "source": [
    "## load Data and make Data augmentation to increase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GY1fX6DGmi34",
    "outputId": "1adc8b61-5ab1-4b2c-c276-8197d7d47e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3087 images belonging to 7 classes.\n",
      "Found 1028 images belonging to 7 classes.\n",
      "Found 1028 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = '/content/drive/MyDrive/Teeth_Dataset/Training'\n",
    "validation_dir = '/content/drive/MyDrive/Teeth_Dataset/Validation'\n",
    "test_dir = '/content/drive/MyDrive/Teeth_Dataset/Testing'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.5, 1.0]\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE2pXQ36J29l"
   },
   "source": [
    "## load model and fine-tune it"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m96/96\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1281s\u001B[0m 13s/step - accuracy: 0.3934 - loss: 2.2758 - val_accuracy: 0.6123 - val_loss: 1.0664\n",
      "Epoch 2/5\n",
      "\u001B[1m 1/96\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m15:08\u001B[0m 10s/step - accuracy: 0.5312 - loss: 1.4540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m96/96\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 17ms/step - accuracy: 0.5312 - loss: 1.4540 - val_accuracy: 0.5000 - val_loss: 1.3853\n",
      "Epoch 3/5\n",
      "\u001B[1m96/96\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10s/step - accuracy: 0.6169 - loss: 1.0575"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the base model\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "for layer in base_model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NoARb20KKTO"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDie_zzKrBnN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get true labels and predictions\n",
    "y_true = test_generator.classes\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=train_generator.class_indices.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
